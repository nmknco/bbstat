#!/usr/bin/env python3

from bs4 import BeautifulSoup
import sys
from urllib.request import *
from urllib.error import *
import json
from pymongo import MongoClient
# from socket import gaierror

def getCollectionFromDb():
    client = MongoClient()
    db = client.database_1
    collection = db.player_collection
    return collection   

def writeToDb(key_bbref, data, collection):
    # data is of the form [{}, {}, ...], generated by
    #   extractData()
    p = collection.update_one(
            {'_id' : key_bbref}, 
            {'$set': { 'data' : data }},
            upsert = True
        )

def readFromDb(key_bbref, collection):
    return collection.find_one({'_id' : key_bbref})

def getData(key_bbref, collection):
    # try getting from collection by default
    #   if data do not exist (or out-of-date), request new data
    data = readFromDb(key_bbref, collection)
    if data != None:
        return data['data'] # real stats is in the 'data' field
    page = getPage(key_bbref)
    if page != 1:
        # print("getPage successful!")
        data = extractData(page)
        writeToDb(key_bbref, data, collection)
        return data
    return 1

def getPage(key_bbref):
    # print("Getting Page For: %s" % key_bbref)
    url = "https://www.baseball-reference.com/players/"
    url += key_bbref[0] + "/" + key_bbref + ".shtml"
    try:
        res = urlopen(url)

        if res.status == 200:
            # print("Success!")
            return res.read().decode('utf8') 
        else:
            print("Failure: " + res.msg)
            return 1
    except (URLError,) as e:
        print(e.code, e.msg)
        return 1

def extractData(page):
    # extrat data in the form of [{}, {}, {}, ...], each item
    #   contains stats from one year
    
    soup = BeautifulSoup(page, 'lxml')
    
    if soup.find(id = "all_batting_value") == None:
        isBatting = False
    elif soup.find(id = "all_pitching_value") == None:
        isBatting = True
    else:
        isBatting = page.index("all_batting_value") < page.index("all_pitching_value")


    keys1 = []
    keys2 = []
    keys3 = [] # keys for retrieving data form bbref
    keys1_name = []
    keys2_name = []
    keys3_name = [] # column names as shown to user

    position_kw = ""

    if isBatting:

        position_kw = "batting"
        # print("Position player")
        keys1 = ["age", "team_ID"]      
        keys2 = ["batting_avg", "onbase_perc", "slugging_perc", "onbase_plus_slugging", # OPS is newly added
                    "G", "PA", "HR", "RBI", "SB", "BB", "SO", 
                    "onbase_plus_slugging_plus"
                ]
        keys3 = ["WAR", "Salary"] 
        keys1_name = ["Age", "Team"]
        keys2_name = ["AVG", "OBP", "SLG", "OPS",
                        "G", "PA", "HR", "RBI", "SB", "BB", "SO",
                        "OPS+"]
        keys3_name = ["WAR", "Salary"]

    else:

        position_kw = "pitching"
        # print("Pitcher")
        keys1 = ["age", "team_ID"]      
        keys2 = ["earned_run_avg", "fip", "whip",
                    "G", "GS", "IP", "earned_run_avg_plus", "hits_per_nine", 
                    "home_runs_per_nine", "bases_on_balls_per_nine", "strikeouts_per_nine"
                ]
        keys3 = ["WAR_pitch", "Salary"] 
        keys1_name = ["Age", "Team"]
        keys2_name = ["ERA", "FIP", "WHIP",
                        "G", "GS", "IP", "ERA+", "H9",
                        "HR9", "BB9", "SO9"]
        keys3_name = ["WAR", "Salary"]

    # rows_clone = table_standard.select('#batting_standard_clone ')
    ## So it turns out that the batting_standard_alone table are somehow dynamically
    ## generated, and in the scraped page the year, age and team are in 
    ## the standard table...

    # tables = soup.select('#content > div')
    # table_standard = tables[1]
    # # print(table_standard)
    # table_value = tables[1]

    try:
        rows_standard_wrapper = soup.find(id = "all_%s_standard" % position_kw).contents[-2]
        # print(rows_standard_wrapper)
        rows_standard = BeautifulSoup(rows_standard_wrapper, 'lxml').select('#%s_standard > tbody > tr' % position_kw)
        # print(rows_standard)
    except TypeError as e:
        rows_standard_wrapper = soup.find(id = "all_%s_standard" % position_kw).contents[3]
        # print(rows_standard_wrapper)
        rows_standard = rows_standard_wrapper.select('#%s_standard > tbody > tr' % position_kw)


    rows_value_wrapper = soup.find(id = "all_%s_value" % position_kw).contents[5]
    rows_value = BeautifulSoup(rows_value_wrapper, 'lxml').select('#%s_value > tbody > tr' % position_kw)

    # value table only contains MLB-active years
    #   ALSO HAS "SPACER" ROWS. see /dimangjo01

    i = 0  # there may be minor league rows in between MLB rows
    j = 0     # in standard table but not in value table
    data = []

    while j < len(rows_value):
        datarow = {}

        # print("%d %d" % (i, j))
        # known row classes:
        # - standard table: minors_table, nonroster_table, partial_table, full
        #   - also has <spacer> class. See /darviyu01
        #       - partial seaons are "partial_table"
        #       - there's an extra TOT(AL) row for partial seasons, that is full
        # - value table: spacer, full
        #       - partial seasons are "full" in value table
        #       - spacer row is also "partial_table"...
        # we write TOT row in standard, but it's going to be incomplete because 
        #   there is no corresponding row in value table
        rs = rows_standard[i]
        # print(rs['class'])
        # two cases to skip i: minors, non-play (injury/military-service)
        # if 'minors_table' in rs['class'] or 'nonroster_table' in rs['class']:
        # Now use negative conditions for more robust coverage
        #   - note that some injury role may have classes: spacer + partial_table
        #       and we need to exclude them
        # So the skip decision tree:
        #   - not full? If not
        #   - not partial_table? If not, skip
        #   - If not full but is partial_table, is it spacer? If so, skip
        #   - If not a spacer, then it is a partial season row and is retained
        # !new 
        #   - There is a further case: NL/AL TOT rows which is just like 
        #       partial seasons (partial_table w/o spacer)
        rsclass = rs['class']
        if ('full' not in rsclass and 'partial_table' not in rsclass or
                'spacer' in rsclass or 
                getTextByStat(rs, "team_ID") == "TOT"
                    # getTextByStat(rs, "lg_ID") != "MLB"): # this is gonna skip good NL/AL TOT rows
                    and 'partial_table' in rsclass):
            i += 1
            continue 

        rv = rows_value[j]
        # print(rs['class'])
        # one case to skip j: spacer row in value table
        if 'spacer' in rv['class']:
            j += 1
            continue
        # dealing with year column separately as it's a <th>
        datarow["Year"] = getText(rs.select('th[data-stat="year_ID"]')[0])

        # get stats from standard table
        for k, kn in zip(keys1+keys2, keys1_name+keys2_name):
            datarow[kn] = getTextByStat(rs, k)
            # print(kn)
            # print(data[kn])
        i += 1

        # print(datarow)
        # get stats from value table: only when standard is not a TOTAL row
        if datarow["Team"] != "TOT":
            for k, kn in zip(keys3, keys3_name):
                datarow[kn] = getTextByStat(rv, k)
                # print(kn)
                # print(data[kn])
            j += 1

        # add a position identifier
        datarow["Position"] =  "F" if isBatting else "P"

        # print(datarow)

        data.append(datarow)


    # filling missing salaries as estimates
    # first iteration: skip all TOT years
    low = 0
    rowToFill = []
    TOTYear = ""
    for row in data:
        skip = row["Year"] == TOTYear # we do not skip the TOT row itself, 
                    # We need the estimate for TOT as a default 
                    # in case salary cells in partial season rows are all 0
        if row["Team"] == "TOT":
            TOTYear = row["Year"]
        salary = row.get("Salary", "")
        if salary != "":
            # add marker
            row["Is_salary_estimate"] = 0
            # $17,200,000 -> 17200000
            salary = int("".join(salary[1:].split(",")))
            row["Salary"] = salary
            # skip partial season rows (but not the TOT row)

            if skip: continue
            # fill empty ones
            for r in rowToFill:
                r["Salary"] = round((low + salary) / 2)
            rowToFill = []
            low = salary
        else:
            row["Is_salary_estimate"] = 1
            if skip: continue
            rowToFill.append(row)
    for r in rowToFill:
        r["Salary"] = low

    # print([row["Salary"] for row in data])

    # second iteration: compute the total salary and war for TOT years
    #   iterating in reverse order to compute sums
    i = 0
    currentYear = -1
    warSum = 0.0
    salarySum = 0
    for row in reversed(data):
        if row["Team"] != "TOT":
            war = row.get("WAR", 0.0)
            salary = row.get("Salary", 0)
            if salary == "": salary = 0
            if war == "": war = 0.0
            war = float(war)
            row["WAR"] = war
            row["Salary"] = salary
            if row["Year"] == currentYear:
                warSum += war
                salarySum += salary
            else:
                currentYear = row["Year"]
                warSum = war
                salarySum = salary
        else:
            row["WAR"] = float("%.1f" % warSum)
            if salarySum > 0: row["Salary"] = salarySum # only use sum when it's not 0
            warSum = 0.0
            salarySum = 0

    # third iteration: estimate the salary for TOT partial years
    totalGame = 0
    totYear = -1
    for row in data:
        if row["Team"] == "TOT":
            totalGame = int(row["G"])
            totYear = row["Year"]
            # get the total salary from te next row
            totalSalary = row["Salary"]
            if salary == -1:
                totalSalary = row["Salary"]
            else:
                row["Salary"] = totalSalary
                row["Is_salary_estimate"] = 0
        elif row["Year"] == totYear:
            row["Salary"] = round(totalSalary * int(row["G"]) / totalGame)
            row["Is_salary_estimate"] = 1



    return data

def getText(tdnode):
    # search down for the textnode content inside
    while tdnode != "" and tdnode.name != None:
        if len(tdnode.contents) > 0:
            tdnode = tdnode.contents[0]
        else:
            tdnode = ""
    return tdnode

def getTextByStat(trnode, stat_name):
    # trnode is usually a row for a year
    return getText(trnode.select('td[data-stat="%s"]'%stat_name)[0])

if __name__ == "__main__":
    key_bbref = sys.argv[1]
    # test: force pull from baseball-reference
    # print(getPage(key_bbref))
    print(extractData(getPage(key_bbref)))

    # collection = getCollectionFromDb()
    # data = getData(key_bbref, collection)
    # if data == 1:
    #     print("{'error': 'cannot get data from baseball-reference'}")
    # else:
    #     print(data)
